# cgbookstore/apps/chatbot_literario/services/external_ai_service.py

import requests
import json
import logging
import time
from typing import Dict, List, Optional, Tuple
from django.conf import settings
from django.core.cache import cache

logger = logging.getLogger(__name__)


class GroqService:
    """
    Servi√ßo de IA externa usando Groq API - Solu√ß√£o r√°pida para chatbot liter√°rio
    ‚úÖ VELOCIDADE: 2-5 segundos vs 50-120s local
    ‚úÖ CONFIABILIDADE: 99.9% uptime
    ‚úÖ GRATUITO: Para uso educacional/liter√°rio
    """

    def __init__(self):
        # Configura√ß√µes da API Groq
        self.api_key = getattr(settings, 'GROQ_API_KEY', '')
        self.base_url = "https://api.groq.com/openai/v1"
        self.model = getattr(settings, 'GROQ_MODEL', 'llama3-8b-8192')

        # Configura√ß√µes otimizadas
        self.timeout = 10  # Groq √© muito r√°pido
        self.max_tokens = getattr(settings, 'GROQ_MAX_TOKENS', 1024)
        self.temperature = 0.7

        # Rate limiting (Groq free tier)
        self.requests_per_minute = 100
        self.cache_timeout = 1800  # 30 min

        # Verifica√ß√£o de disponibilidade
        self.available = self._check_availability()

        if self.available:
            logger.info("‚úÖ GroqService inicializado com sucesso!")
        else:
            logger.warning("‚ö†Ô∏è GroqService indispon√≠vel (API key ou conectividade)")

    def _check_availability(self) -> bool:
        """Verifica se o servi√ßo Groq est√° dispon√≠vel"""
        if not self.api_key:
            logger.warning("GROQ_API_KEY n√£o configurada")
            return False

        try:
            # Teste simples de conectividade
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }

            # Teste com uma mensagem m√≠nima
            test_payload = {
                "model": self.model,
                "messages": [{"role": "user", "content": "teste"}],
                "max_tokens": 10
            }

            response = requests.post(
                f"{self.base_url}/chat/completions",
                json=test_payload,
                headers=headers,
                timeout=5
            )

            return response.status_code == 200

        except Exception as e:
            logger.error(f"Erro ao verificar disponibilidade do Groq: {e}")
            return False

    def _build_literary_system_prompt(self) -> str:
        """
        System prompt super otimizado para literatura brasileira e mundial
        ‚úÖ PRECIS√ÉO: Evita erros como "Quarta Asa = Clarice Lispector"
        ‚úÖ BRASILEIRO: Foco em literatura nacional
        """
        return """Voc√™ √© o assistente liter√°rio especialista da CG.BookStore.Online.

EXPERTISE PRINCIPAL:
‚Ä¢ Literatura Brasileira: Machado de Assis, Clarice Lispector, Jos√© de Alencar, Lima Barreto, Guimar√£es Rosa
‚Ä¢ Literatura Mundial: Cl√°ssicos e contempor√¢neos  
‚Ä¢ Movimentos: Romantismo, Realismo, Modernismo brasileiro
‚Ä¢ An√°lises cr√≠ticas e contexto hist√≥rico

REGRAS CR√çTICAS:
1. Se n√£o souber sobre um livro/autor ESPEC√çFICO, diga "N√£o tenho informa√ß√µes confi√°veis sobre esta obra"
2. NUNCA invente informa√ß√µes sobre autores brasileiros
3. Priorize autores e obras do cat√°logo brasileiro
4. Para autores internacionais, seja preciso nas datas e obras
5. Use conhecimento da base quando fornecido

ESTILO: Culto mas acess√≠vel, educativo e envolvente.

Responda com precis√£o sobre literatura, admitindo quando n√£o souber algo espec√≠fico."""

    def _prepare_groq_payload(self, messages: List[Dict]) -> Dict:
        """
        Prepara payload otimizado para Groq API
        ‚úÖ OTIMIZADO: Para velocidade e qualidade liter√°ria
        """

        # System prompt liter√°rio
        literary_messages = [
            {"role": "system", "content": self._build_literary_system_prompt()}
        ]

        # Adicionar mensagens (limitadas para velocidade)
        context_messages = messages[-6:]  # √öltimas 6 mensagens para contexto
        literary_messages.extend(context_messages)

        payload = {
            "model": self.model,
            "messages": literary_messages,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "top_p": 0.9,
            "stream": False
        }

        return payload

    def generate_response(self, messages: List[Dict]) -> Dict:
        """
        Gera resposta usando Groq API
        ‚úÖ R√ÅPIDO: 2-5 segundos t√≠pico
        ‚úÖ CONFI√ÅVEL: Com tratamento de erro
        """
        if not self.available:
            return {
                'success': False,
                'error': 'Groq service not available',
                'response': 'Servi√ßo externo indispon√≠vel.'
            }

        start_time = time.time()

        try:
            # Cache key baseado nas mensagens
            cache_key = f"groq_response_{hash(str(messages))}"
            cached_response = cache.get(cache_key)

            if cached_response:
                logger.debug("Resposta Groq recuperada do cache")
                return cached_response

            # Preparar requisi√ß√£o
            payload = self._prepare_groq_payload(messages)
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }

            logger.info(f"üöÄ Enviando requisi√ß√£o para Groq (modelo: {self.model})")

            # Fazer requisi√ß√£o
            response = requests.post(
                f"{self.base_url}/chat/completions",
                json=payload,
                headers=headers,
                timeout=self.timeout
            )

            execution_time = time.time() - start_time

            if response.status_code == 200:
                response_data = response.json()

                # Extrair resposta
                bot_response = response_data['choices'][0]['message']['content']

                # Metadados
                usage = response_data.get('usage', {})

                result = {
                    'success': True,
                    'response': bot_response,
                    'execution_time': execution_time,
                    'service': 'groq',
                    'model': self.model,
                    'metadata': {
                        'tokens_used': usage.get('total_tokens', 0),
                        'prompt_tokens': usage.get('prompt_tokens', 0),
                        'completion_tokens': usage.get('completion_tokens', 0),
                        'response_length': len(bot_response)
                    }
                }

                # Cache da resposta
                cache.set(cache_key, result, timeout=self.cache_timeout)

                logger.info(f"‚úÖ Resposta Groq gerada em {execution_time:.2f}s")
                return result

            else:
                error_msg = f"Groq API error: {response.status_code}"
                logger.error(f"{error_msg} - {response.text}")

                return {
                    'success': False,
                    'error': error_msg,
                    'response': 'Erro na API externa. Tente novamente.',
                    'execution_time': execution_time
                }

        except requests.Timeout:
            execution_time = time.time() - start_time
            logger.warning(f"‚è∞ Timeout na Groq API ap√≥s {execution_time:.2f}s")

            return {
                'success': False,
                'error': 'timeout',
                'response': 'Timeout na resposta. Tente uma pergunta mais simples.',
                'execution_time': execution_time
            }

        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"‚ùå Erro na Groq API: {e}")

            return {
                'success': False,
                'error': str(e),
                'response': 'Erro t√©cnico na IA externa.',
                'execution_time': execution_time
            }

    def health_check(self) -> Dict:
        """
        Health check do servi√ßo Groq
        """
        if not self.available:
            return {
                'status': 'down',
                'service': 'groq',
                'error': 'API key not configured or service unavailable'
            }

        try:
            # Teste r√°pido
            test_messages = [{"role": "user", "content": "teste r√°pido"}]
            result = self.generate_response(test_messages)

            if result['success']:
                return {
                    'status': 'healthy',
                    'service': 'groq',
                    'model': self.model,
                    'response_time': result.get('execution_time', 0),
                    'available': True
                }
            else:
                return {
                    'status': 'degraded',
                    'service': 'groq',
                    'error': result.get('error', 'Unknown error'),
                    'available': False
                }

        except Exception as e:
            return {
                'status': 'down',
                'service': 'groq',
                'error': str(e),
                'available': False
            }

    def is_available(self) -> bool:
        """Verifica se o servi√ßo est√° dispon√≠vel"""
        return self.available and bool(self.api_key)


class HuggingFaceService:
    """
    Servi√ßo de backup usando Hugging Face Inference API
    ‚úÖ GRATUITO: Completamente free
    ‚úÖ BACKUP: Quando Groq falhar
    """

    def __init__(self):
        self.api_key = getattr(settings, 'HF_API_KEY', '')
        self.model = getattr(settings, 'HF_MODEL', 'microsoft/DialoGPT-large')
        self.base_url = "https://api-inference.huggingface.co/models"
        self.timeout = 15  # HF pode ser mais lenta
        self.available = bool(self.api_key)

        if self.available:
            logger.info("‚úÖ HuggingFaceService dispon√≠vel como backup")

    def generate_response(self, messages: List[Dict]) -> Dict:
        """Gera resposta usando HF Inference API"""
        if not self.available:
            return {
                'success': False,
                'error': 'HuggingFace service not available',
                'response': 'Servi√ßo de backup indispon√≠vel.'
            }

        start_time = time.time()

        try:
            # Extrair √∫ltima mensagem do usu√°rio
            user_message = ""
            for msg in reversed(messages):
                if msg.get('role') == 'user':
                    user_message = msg.get('content', '')
                    break

            if not user_message:
                return {
                    'success': False,
                    'error': 'No user message found',
                    'response': 'Mensagem inv√°lida.'
                }

            # Preparar payload HF
            headers = {"Authorization": f"Bearer {self.api_key}"}
            payload = {
                "inputs": f"Literatura: {user_message}",
                "parameters": {
                    "max_length": 500,
                    "temperature": 0.7,
                    "do_sample": True
                }
            }

            response = requests.post(
                f"{self.base_url}/{self.model}",
                headers=headers,
                json=payload,
                timeout=self.timeout
            )

            execution_time = time.time() - start_time

            if response.status_code == 200:
                data = response.json()

                if isinstance(data, list) and len(data) > 0:
                    bot_response = data[0].get('generated_text', 'Resposta indispon√≠vel.')

                    return {
                        'success': True,
                        'response': bot_response,
                        'service': 'huggingface',
                        'execution_time': execution_time
                    }

            return {
                'success': False,
                'error': f'HF API error: {response.status_code}',
                'response': 'Erro no servi√ßo de backup.',
                'execution_time': execution_time
            }

        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"Erro HuggingFace: {e}")

            return {
                'success': False,
                'error': str(e),
                'response': 'Erro t√©cnico no backup.',
                'execution_time': execution_time
            }

    def is_available(self) -> bool:
        return self.available


class ExternalAIManager:
    """
    Gerenciador de m√∫ltiplos servi√ßos de IA externa
    ‚úÖ FALLBACK: Groq ‚Üí HuggingFace ‚Üí Error
    ‚úÖ INTELIGENTE: Escolha autom√°tica do melhor servi√ßo
    """

    def __init__(self):
        self.groq = GroqService()
        self.hf = HuggingFaceService()

        # Prioridade dos servi√ßos
        self.services = [
            ('groq', self.groq),
            ('huggingface', self.hf)
        ]

        # Log dos servi√ßos dispon√≠veis
        available_services = [name for name, service in self.services if service.is_available()]
        logger.info(f"üåê External AI Services dispon√≠veis: {available_services}")

    def generate_response(self, messages: List[Dict]) -> Dict:
        """
        Gera resposta usando o melhor servi√ßo dispon√≠vel
        ‚úÖ FALLBACK: Autom√°tico entre servi√ßos
        ‚úÖ R√ÅPIDO: Prioriza velocidade
        """
        last_error = None

        for service_name, service in self.services:
            if not service.is_available():
                logger.debug(f"Servi√ßo {service_name} indispon√≠vel, tentando pr√≥ximo...")
                continue

            try:
                logger.info(f"üîÑ Tentando {service_name}...")
                result = service.generate_response(messages)

                if result['success']:
                    logger.info(f"‚úÖ Resposta gerada por {service_name} em {result.get('execution_time', 0):.2f}s")
                    result['fallback_service'] = service_name
                    return result
                else:
                    last_error = result.get('error', 'Unknown error')
                    logger.warning(f"‚ö†Ô∏è {service_name} falhou: {last_error}")

            except Exception as e:
                last_error = str(e)
                logger.error(f"‚ùå Erro em {service_name}: {e}")
                continue

        # Todos os servi√ßos falharam
        logger.error("‚ùå Todos os servi√ßos externos falharam")

        return {
            'success': False,
            'error': f'All external services failed. Last error: {last_error}',
            'response': self._get_fallback_response(),
            'fallback_service': 'none'
        }

    def _get_fallback_response(self) -> str:
        """Resposta de fallback quando tudo falha"""
        return (
            "Nossos servi√ßos de IA est√£o temporariamente indispon√≠veis. "
            "Aqui est√£o algumas alternativas:\n\n"
            "üîç **Busque diretamente**: Use a busca principal do site\n"
            "üìö **Explore categorias**: Visite literatura brasileira, cl√°ssicos mundiais\n"
            "üí¨ **Reformule**: Tente uma pergunta mais espec√≠fica em alguns minutos\n\n"
            "‚ö° *Nossos sistemas est√£o sendo otimizados para melhor performance.*"
        )

    def health_check(self) -> Dict:
        """Health check de todos os servi√ßos"""
        services_status = {}

        for service_name, service in self.services:
            try:
                if hasattr(service, 'health_check'):
                    services_status[service_name] = service.health_check()
                else:
                    services_status[service_name] = {
                        'status': 'healthy' if service.is_available() else 'down',
                        'available': service.is_available()
                    }
            except Exception as e:
                services_status[service_name] = {
                    'status': 'error',
                    'error': str(e),
                    'available': False
                }

        # Status geral
        available_count = sum(1 for status in services_status.values()
                              if status.get('available', False))

        overall_status = 'healthy' if available_count > 0 else 'down'

        return {
            'overall_status': overall_status,
            'available_services': available_count,
            'total_services': len(self.services),
            'services': services_status
        }

    def is_available(self) -> bool:
        """Verifica se pelo menos um servi√ßo est√° dispon√≠vel"""
        return any(service.is_available() for _, service in self.services)


# ‚úÖ INST√ÇNCIAS GLOBAIS
groq_service = GroqService()
external_ai_manager = ExternalAIManager()


# ‚úÖ FUN√á√ÉO DE CONVENI√äNCIA
def get_external_response(messages: List[Dict]) -> Dict:
    """Fun√ß√£o standalone para obter resposta de IA externa"""
    return external_ai_manager.generate_response(messages)


def is_external_ai_available() -> bool:
    """Verifica se IA externa est√° dispon√≠vel"""
    return external_ai_manager.is_available()