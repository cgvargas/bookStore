# cgbookstore/apps/chatbot_literario/management/commands/ollama.py

from django.core.management.base import BaseCommand, CommandError
from django.conf import settings
import requests
import logging

# ‚úÖ CORRE√á√ÉO: Importar as inst√¢ncias de servi√ßo e fun√ß√µes corretas e atuais
from cgbookstore.apps.chatbot_literario.services import ai_service, is_ai_available, functional_chatbot

# from cgbookstore.apps.chatbot_literario.services.embeddings import embeddings_service # Descomente se precisar

logger = logging.getLogger(__name__)


class Command(BaseCommand):
    help = 'Gerencia e diagnostica o servi√ßo Ollama para o chatbot liter√°rio.'

    def add_arguments(self, parser):
        parser.add_argument(
            'action',
            type=str,
            nargs='?',
            default='status',
            choices=['status', 'test'],  # Simplificado para os comandos que funcionam
            help='A√ß√£o a ser executada (status, test).',
        )
        parser.add_argument(
            '--prompt',
            type=str,
            default='Ol√°! Em uma frase, quem √© voc√™?',
            help='Prompt para o subcomando de teste.'
        )

    def handle(self, *args, **options):
        action = options['action']

        self.stdout.write(f"Ambiente de: {settings.DEBUG and 'development' or 'production'}")

        if action == 'status':
            self.show_status()
        elif action == 'test':
            self.test_prompt(options['prompt'])
        else:
            raise CommandError(f"A√ß√£o desconhecida: '{action}'. Use 'status' ou 'test'.")

    def show_status(self):
        """Exibe o status completo dos servi√ßos de IA."""
        self.stdout.write(self.style.SUCCESS("\nüìä Verificando status dos servi√ßos de IA..."))

        # 1. Configura√ß√µes do Django
        self.stdout.write("\n" + self.style.WARNING("üîß Configura√ß√£o Django:"))
        try:
            # Tenta ler do dicion√°rio primeiro (melhor pr√°tica)
            ollama_config = settings.OLLAMA_CONFIG
            enabled = ollama_config.get('enabled')
            model = ollama_config.get('model')
            url = ollama_config.get('base_url')
        except AttributeError:
            # Fallback para vari√°veis soltas (compatibilidade)
            enabled = getattr(settings, 'USE_OLLAMA', False)
            model = getattr(settings, 'OLLAMA_MODEL', None)
            url = getattr(settings, 'OLLAMA_URL', None)

        self.stdout.write(f"  Habilitado: {'‚úÖ' if enabled else '‚ùå'}")
        self.stdout.write(f"  Modelo configurado: {model}")
        self.stdout.write(f"  URL: {url}")

        # 2. Status do AI Service (Ollama)
        self.stdout.write("\n" + self.style.WARNING("ü§ñ AI Service (Ollama):"))
        if is_ai_available():
            self.stdout.write(f"  Status: {'‚úÖ Dispon√≠vel'}")
            self.stdout.write(f"  URL: {ai_service.ollama_url}")
        else:
            self.stdout.write(self.style.ERROR("  Status: ‚ùå Indispon√≠vel"))
            self.stdout.write(f"  -> Verifique se o Ollama est√° rodando em {getattr(settings, 'OLLAMA_URL', url)}")

        # 3. Status do Chatbot Funcional
        self.stdout.write("\n" + self.style.WARNING("üí¨ Chatbot Funcional (Sess√µes em Mem√≥ria):"))
        try:
            stats = functional_chatbot.get_statistics()
            self.stdout.write(f"  Sess√µes ativas: {stats.get('active_sessions', 'N/A')}")
            self.stdout.write(f"  Total de mensagens no hist√≥rico: {stats.get('total_messages', 'N/A')}")
        except Exception as e:
            self.stdout.write(self.style.ERROR(f"  N√£o foi poss√≠vel obter estat√≠sticas do chatbot: {e}"))

        self.stdout.write(self.style.SUCCESS("\nVerifica√ß√£o de status conclu√≠da."))

    def test_prompt(self, prompt_text: str):
        """Envia um prompt de teste para o Ollama atrav√©s da nossa camada de servi√ßo."""
        self.stdout.write(self.style.SUCCESS(f"\nüß™ Enviando prompt de teste: '{prompt_text}'"))

        # ‚úÖ CORRE√á√ÉO: Usa a interface correta, que espera uma lista de mensagens
        messages_for_ai = [{"role": "user", "content": prompt_text}]

        response = ai_service.generate_response(messages_for_ai)

        if response.get('success'):
            self.stdout.write(self.style.SUCCESS("‚úÖ Resposta recebida com sucesso!"))
            self.stdout.write(f"   Modelo ({response.get('model_used')}): '{response.get('response')}'")
        else:
            self.stdout.write(self.style.ERROR("‚ùå Falha ao obter resposta do Ollama."))
            self.stdout.write(f"   Erro: {response.get('error', 'Desconhecido')}")