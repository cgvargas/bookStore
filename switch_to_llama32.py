#!/usr/bin/env python
"""
Script para trocar modelo do AI Service para Llama 3.2
ExecuÃ§Ã£o: python switch_to_llama32.py
"""

import os
import sys
import django
import requests
import json
import time

# Configurar Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'cgbookstore.config.settings')
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
django.setup()

from cgbookstore.apps.chatbot_literario.services.ai_service import ai_service


def test_model(model_name):
    """Testa um modelo especÃ­fico"""
    print(f"ğŸ”§ Testando modelo: {model_name}")

    try:
        payload = {
            "model": model_name,
            "messages": [
                {"role": "system", "content": "VocÃª Ã© um assistente literÃ¡rio da CG.BookStore."},
                {"role": "user", "content": "Quem escreveu Dom Casmurro? Responda em uma frase."}
            ],
            "stream": False,
            "options": {
                "temperature": 0.3,
                "num_predict": 100,
                "num_ctx": 2048
            }
        }

        start_time = time.time()
        response = requests.post(
            "http://localhost:11434/api/chat",
            json=payload,
            timeout=60,
            headers={'Content-Type': 'application/json'}
        )
        duration = time.time() - start_time

        if response.status_code == 200:
            result = response.json()
            content = result.get('message', {}).get('content', '')
            print(f"   âœ… Sucesso em {duration:.1f}s: {len(content)} chars")
            print(f"   ğŸ“ Resposta: {content.strip()}")
            return True, content.strip()
        else:
            error_msg = response.text
            print(f"   âŒ Erro HTTP {response.status_code}: {error_msg}")
            return False, error_msg

    except Exception as e:
        print(f"   âŒ ExceÃ§Ã£o: {e}")
        return False, str(e)


def main():
    print("ğŸš€ TROCA DE MODELO PARA LLAMA 3.2")
    print("=" * 50)

    # Verificar modelos disponÃ­veis
    print("ğŸ“‹ Verificando modelos disponÃ­veis...")
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=10)
        if response.status_code == 200:
            models = response.json().get('models', [])
            print("âœ… Modelos encontrados:")
            for model in models:
                size_gb = model['size'] / 1e9
                print(f"   ğŸ“¦ {model['name']} ({size_gb:.1f}GB)")
        else:
            print("âŒ Erro ao listar modelos")
            return False
    except Exception as e:
        print(f"âŒ Erro: {e}")
        return False

    # Testar modelos menores
    test_models = ["llama3.2:3b", "llama3.2:latest"]
    working_model = None

    for model in test_models:
        print(f"\nğŸ§ª Testando {model}...")
        success, response = test_model(model)
        if success:
            working_model = model
            print(f"âœ… {model} funcionando perfeitamente!")
            break
        else:
            print(f"âŒ {model} falhou")

    if not working_model:
        print("\nâŒ NENHUM MODELO FUNCIONOU!")
        print("ğŸ’¡ SoluÃ§Ã£o: Aumentar RAM ou usar modelo ainda menor")
        return False

    # Atualizar AI Service
    print(f"\nğŸ”„ Atualizando AI Service para usar {working_model}...")

    old_model = ai_service.model
    ai_service.model = working_model

    print(f"   ğŸ“Š Modelo anterior: {old_model}")
    print(f"   ğŸ“Š Novo modelo: {ai_service.model}")

    # Testar novo modelo no AI Service
    print(f"\nğŸ§ª Testando AI Service com {working_model}...")

    try:
        messages = [
            {"role": "system", "content": "VocÃª Ã© um assistente literÃ¡rio da CG.BookStore."},
            {"role": "user", "content": "Quem escreveu Dom Casmurro?"}
        ]

        result = ai_service.generate_response(messages)

        if result.get('success'):
            response_text = result.get('response', '')
            print(f"   âœ… AI Service funcionando: {len(response_text)} chars")
            print(f"   ğŸ“ Resposta: {response_text[:150]}...")
            print(f"   âš¡ EstratÃ©gia: {result.get('response_strategy', 'N/A')}")

            # Verificar se nÃ£o Ã© fallback
            if result.get('response_strategy') != 'final_fallback':
                print("   ğŸ‰ PROBLEMA RESOLVIDO!")

                # Salvar configuraÃ§Ã£o (informativo)
                print(f"\nğŸ’¾ Para tornar permanente, atualize o settings.py:")
                print(f"   OLLAMA_MODEL = '{working_model}'")

                return True
            else:
                print("   âš ï¸ Ainda caindo no fallback...")
                return False
        else:
            print(f"   âŒ Erro: {result.get('error', 'Desconhecido')}")
            return False

    except Exception as e:
        print(f"   âŒ ExceÃ§Ã£o: {e}")
        return False


if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ SUCESSO! Sistema funcionando com novo modelo!")
        print("ğŸš€ Execute: python manage.py test_system --test-chat")
    else:
        print("\nâŒ FALHA! Problemas persistem.")

    sys.exit(0 if success else 1)